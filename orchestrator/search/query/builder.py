# Copyright 2019-2025 SURF, GÃ‰ANT.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from collections import defaultdict
from typing import Any, Sequence

from pydantic import BaseModel, ConfigDict
from sqlalchemy import Select, String, case, cast, func, select
from sqlalchemy.engine import Row
from sqlalchemy.sql.elements import Label
from sqlalchemy.sql.selectable import CTE
from sqlalchemy_utils.types.ltree import Ltree

from orchestrator.db.models import AiSearchIndex
from orchestrator.search.core.types import ActionType, EntityType, FieldType, FilterOp, UIType
from orchestrator.search.filters import LtreeFilter
from orchestrator.search.query.models import BaseQuery


class LeafInfo(BaseModel):
    """Information about a leaf (terminal field) in the entity schema."""

    name: str
    ui_types: list[UIType]
    paths: list[str]

    model_config = ConfigDict(
        extra="forbid",
        use_enum_values=True,
    )


class ComponentInfo(BaseModel):
    """Information about a component (nested object) in the entity schema."""

    name: str
    ui_types: list[UIType]

    model_config = ConfigDict(
        extra="forbid",
        use_enum_values=True,
    )


def create_path_autocomplete_lquery(prefix: str) -> str:
    """Create the lquery pattern for a multi-level path autocomplete search."""
    return f"{prefix}*.*"


def build_candidate_query(params: BaseQuery) -> Select:
    """Build the base query for retrieving candidate entities.

    Constructs a `SELECT` statement that retrieves distinct `entity_id` values
    from the index table for the given entity type, applying any structured
    filters from the provided search parameters.

    Args:
        params (BaseQuery): The search parameters containing the entity type and optional filters.

    Returns:
        Select: The SQLAlchemy `Select` object representing the query.
    """

    stmt = (
        select(AiSearchIndex.entity_id, AiSearchIndex.entity_title)
        .where(AiSearchIndex.entity_type == params.entity_type.value)
        .distinct()
    )

    if params.filters is not None:
        entity_id_col = AiSearchIndex.entity_id
        stmt = stmt.where(
            params.filters.to_expression(
                entity_id_col,
                entity_type_value=params.entity_type.value,
            )
        )

    return stmt


def build_paths_query(entity_type: EntityType, prefix: str | None = None, q: str | None = None) -> Select:
    """Build the query for retrieving paths and their value types for leaves/components processing."""
    stmt = select(AiSearchIndex.path, AiSearchIndex.value_type).where(AiSearchIndex.entity_type == entity_type.value)

    if prefix:
        lquery_pattern = create_path_autocomplete_lquery(prefix)
        ltree_filter = LtreeFilter(op=FilterOp.MATCHES_LQUERY, value=lquery_pattern)
        stmt = stmt.where(ltree_filter.to_expression(AiSearchIndex.path, path=""))

    stmt = stmt.group_by(AiSearchIndex.path, AiSearchIndex.value_type)

    if q:
        score = func.similarity(cast(AiSearchIndex.path, String), q)
        stmt = stmt.order_by(score.desc(), AiSearchIndex.path)
    else:
        stmt = stmt.order_by(AiSearchIndex.path)

    return stmt


def process_path_rows(rows: Sequence[Row]) -> tuple[list[LeafInfo], list[ComponentInfo]]:
    """Process query results to extract leaves and components information.

    Parameters
    ----------
    rows : Sequence[Row]
        Database rows containing path and value_type information

    Returns:
    -------
    tuple[list[LeafInfo], list[ComponentInfo]]
        Processed leaves and components
    """
    leaves_dict: dict[str, set[UIType]] = defaultdict(set)
    leaves_paths_dict: dict[str, set[str]] = defaultdict(set)
    components_set: set[str] = set()

    for row in rows:
        path, value_type = row

        path_str = str(path)
        path_segments = path_str.split(".")

        # Remove numeric segments
        clean_segments = [seg for seg in path_segments if not seg.isdigit()]

        if clean_segments:
            # Last segment is a leaf
            leaf_name = clean_segments[-1]
            ui_type = UIType.from_field_type(FieldType(value_type))
            leaves_dict[leaf_name].add(ui_type)
            leaves_paths_dict[leaf_name].add(path_str)

            # All segments except the first/last are components
            for component in clean_segments[1:-1]:
                components_set.add(component)

    leaves = [
        LeafInfo(name=leaf, ui_types=list(types), paths=sorted(leaves_paths_dict[leaf]))
        for leaf, types in leaves_dict.items()
    ]
    components = [ComponentInfo(name=component, ui_types=[UIType.COMPONENT]) for component in sorted(components_set)]

    return leaves, components


def _build_pivot_cte(base_query: Select, pivot_fields: list[str]) -> CTE:
    """Build CTE that pivots EAV rows into columns using CASE WHEN."""
    from orchestrator.search.aggregations import BaseAggregation

    pivot_columns = [AiSearchIndex.entity_id.label("entity_id")]

    for field_path in pivot_fields:
        pivot_columns.append(
            func.max(case((AiSearchIndex.path == Ltree(field_path), AiSearchIndex.value), else_=None)).label(
                BaseAggregation.field_to_alias(field_path)
            )
        )

    return (
        select(*pivot_columns)
        .where(
            AiSearchIndex.entity_id.in_(select(base_query.c.entity_id)),
            AiSearchIndex.path.in_([Ltree(p) for p in pivot_fields]),
        )
        .group_by(AiSearchIndex.entity_id)
        .cte("pivoted_entities")
    )


def _build_grouping_columns(params: BaseQuery, pivot_cte: CTE) -> tuple[list[Any], list[Any], list[str]]:
    """Build GROUP BY columns and their SELECT columns.

    Returns:
        tuple: (select_columns, group_by_columns, group_column_names)
            - select_columns: List of labeled columns for SELECT
            - group_by_columns: List of columns for GROUP BY clause
            - group_column_names: List of column names (labels) that are grouping columns
    """
    from orchestrator.search.aggregations import BaseAggregation

    select_columns = []
    group_by_columns = []
    group_column_names = []

    if params.group_by:
        for group_field in params.group_by:
            field_alias = BaseAggregation.field_to_alias(group_field)
            col = getattr(pivot_cte.c, field_alias)
            select_columns.append(col.label(field_alias))
            group_by_columns.append(col)
            group_column_names.append(field_alias)

    if params.temporal_group_by:
        for temp_group in params.temporal_group_by:
            select_col, group_col, col_name = temp_group.to_expression(pivot_cte.c)
            select_columns.append(select_col)
            group_by_columns.append(group_col)
            group_column_names.append(col_name)

    return select_columns, group_by_columns, group_column_names


def _build_aggregation_columns(params: BaseQuery, pivot_cte: CTE) -> list[Label]:
    """Build aggregation columns (COUNT, SUM, AVG, MIN, MAX)."""
    from orchestrator.search.aggregations import AggregationType, CountAggregation

    if params.action == ActionType.COUNT:
        count_agg = CountAggregation(type=AggregationType.COUNT, alias="count")
        return [count_agg.to_expression(pivot_cte.c.entity_id)]

    if params.action == ActionType.AGGREGATE and params.aggregations:
        agg_columns = []
        for agg in params.aggregations:
            if isinstance(agg, CountAggregation):
                agg_columns.append(agg.to_expression(pivot_cte.c.entity_id))
            else:
                agg_columns.append(agg.to_expression(pivot_cte.c))
        return agg_columns

    return []


def build_aggregation_query(params: BaseQuery, base_query: Select) -> tuple[Select, list[str]]:
    """Build aggregation query with GROUP BY and aggregation functions.

    Handles EAV storage by pivoting rows to columns, then applying SQL aggregations.
    This function only handles grouped aggregations. Simple counts are handled directly
    in the engine.

    Args:
        params: Search parameters including group_by and aggregations
        base_query: Base candidate query with filters applied

    Returns:
        tuple: (query, group_column_names)
            - query: SQLAlchemy Select statement for grouped aggregation
            - group_column_names: List of column names that are grouping columns
    """
    pivot_cte = _build_pivot_cte(base_query, params.get_pivot_fields())
    select_cols, group_cols, group_col_names = _build_grouping_columns(params, pivot_cte)
    agg_cols = _build_aggregation_columns(params, pivot_cte)

    stmt = select(*(select_cols + agg_cols)).select_from(pivot_cte)
    if group_cols:
        stmt = stmt.group_by(*group_cols)

    return stmt, group_col_names
